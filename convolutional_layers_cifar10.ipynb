{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks on CIFAR-10\n",
    "\n",
    "## Context and Motivation\n",
    "In this course, neural networks are not treated as black boxes but as architectural components whose design choices affect performance, scalability, and interpretability. This assignment focuses on convolutional layers as a concrete example of how inductive bias is introduced into learning systems. Rather than following a recipe, we analyze and experiment with a convolutional architecture using a real dataset (CIFAR-10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Understand the role and intuition behind convolutional layers\n",
    "- Analyze architectural decisions (kernel size, depth, stride, padding)\n",
    "- Compare convolutional and fully connected models\n",
    "- Perform a minimal exploratory data analysis (EDA)\n",
    "- Communicate architectural and experimental decisions clearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Selection and Justification\n",
    "CIFAR-10 is a standard benchmark dataset for image classification consisting of small natural images. It is appropriate for convolutional networks because it exhibits spatial locality, local patterns (edges, textures), and translation invariance, which align well with the inductive bias of convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "We inspect dataset size, image shape, and class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training samples:', x_train.shape)\n",
    "print('Test samples:', x_test.shape)\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "pd.DataFrame({'Class': unique.flatten(), 'Count': counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "plt.figure(figsize=(8,4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.title(class_names[y_train[i][0]])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model (Fully Connected)\n",
    "A simple non-convolutional network serves as a reference point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(32,32,3)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "fc_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_history = fc_model.fit(x_train, y_train, epochs=5, validation_split=0.1, verbose=2)\n",
    "fc_test_loss, fc_test_acc = fc_model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Model Design\n",
    "We design a simple CNN using small kernels (3×3), ReLU activations, and max pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_3x3 = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(32,32,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "cnn_3x3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_3x3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_history = cnn_3x3.fit(x_train, y_train, epochs=5, validation_split=0.1, verbose=2)\n",
    "cnn_test_loss, cnn_test_acc = cnn_3x3.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlled Experiment: Kernel Size (5×5)\n",
    "We keep all components fixed and only change the kernel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_5x5 = models.Sequential([\n",
    "    layers.Conv2D(32, (5,5), activation='relu', padding='same', input_shape=(32,32,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (5,5), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "cnn_5x5.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_5x5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn5_history = cnn_5x5.fit(x_train, y_train, epochs=5, validation_split=0.1, verbose=2)\n",
    "loss_5x5, acc_5x5 = cnn_5x5.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Fully Connected', 'CNN 3x3', 'CNN 5x5'],\n",
    "    'Test Accuracy': [fc_test_acc, cnn_test_acc, acc_5x5]\n",
    "})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation and Architectural Reasoning\n",
    "Convolutional models outperform the fully connected baseline due to their inductive bias toward spatial locality and translation invariance. Smaller kernels (3×3) achieve comparable or better performance with fewer parameters. Convolution is less suitable for data without spatial structure or stationarity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
