{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Convolutional Neural Networks Assignment\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand convolutional layers and their inductive bias\n",
    "- Analyze architectural design choices (kernel size, depth, stride, padding)\n",
    "- Compare CNNs with fully connected baseline models\n",
    "- Deploy the model to AWS SageMaker\n",
    "\n",
    "## Dataset: CIFAR-10\n",
    "CIFAR-10 is a 32x32 RGB image dataset with 10 classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck). It contains 50,000 training images and 10,000 test images."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "# Load Dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print(\"Training data shape:\", x_train.shape)\n",
    "print(\"Testing data shape:\", x_test.shape)\n",
    "\n",
    "# Visualize Sample Images\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.title(f'Label: {y_train[i][0]}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Flatten Data for Baseline\n",
    "x_train_flat = x_train.reshape(-1, 32 * 32 * 3)\n",
    "x_test_flat = x_test.reshape(-1, 32 * 32 * 3)\n",
    "\n",
    "# Baseline Model (Dense only)\n",
    "baseline_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(32 * 32 * 3,)),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "baseline_model.compile(optimizer='adam',\n",
    "                       loss='sparse_categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "baseline_model.fit(x_train_flat, y_train,\n",
    "                   epochs=10,\n",
    "                   validation_data=(x_test_flat, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(x_train, y_train,\n",
    "              epochs=10,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Controlled Experiments on Kernel Size\n",
    "kernel_sizes = [(3, 3), (5, 5), (7, 7)]\n",
    "for size in kernel_sizes:\n",
    "    print(f\"\\nTraining with kernel size {size}\")\n",
    "    model = Sequential([\n",
    "        Conv2D(32, kernel_size=size, activation='relu', input_shape=(32, 32, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "              epochs=5,\n",
    "              validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Placeholder for SageMaker Deployment\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "# Example skeleton (requires AWS setup):\n",
    "# estimator = TensorFlow(entry_point='train.py',\n",
    "#                        role='SageMakerRole',\n",
    "#                        instance_type='ml.m5.large',\n",
    "#                        framework_version='2.3',\n",
    "#                        py_version='py37')\n",
    "# estimator.fit({'training': 's3://bucket/cifar10/train'})\n",
    "# predictor = estimator.deploy(initial_instance_count=1,\n",
    "#                              instance_type='ml.m5.large')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
