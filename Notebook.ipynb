{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Convolutional Layers Through Data and Experiments\n",
    "\n",
    "## Step 1: Dataset Exploration (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations (minimal for EDA)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Download and load training set\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Download and load test set\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(trainset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Dataset Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names\n",
    "class_names = trainset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"\\nNumber of classes: {num_classes}\")\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "# Check image dimensions\n",
    "sample_img, sample_label = trainset[0]\n",
    "print(f\"\\nImage tensor shape: {sample_img.shape}\")\n",
    "print(f\"Image dimensions: {sample_img.shape[1]} x {sample_img.shape[2]} pixels\")\n",
    "print(f\"Channels: {sample_img.shape[0]}\")\n",
    "print(f\"Data type: {sample_img.dtype}\")\n",
    "print(f\"Min value: {sample_img.min():.3f}, Max value: {sample_img.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count samples per class\n",
    "train_labels = [label for _, label in trainset]\n",
    "label_counts = Counter(train_labels)\n",
    "\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "for class_idx, class_name in enumerate(class_names):\n",
    "    count = label_counts[class_idx]\n",
    "    print(f\"  {class_name}: {count} samples\")\n",
    "\n",
    "# Visualize distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "classes_sorted = sorted(class_names, key=lambda x: label_counts[class_names.index(x)])\n",
    "counts = [label_counts[class_names.index(c)] for c in classes_sorted]\n",
    "\n",
    "ax.bar(range(len(classes_sorted)), counts, color='steelblue')\n",
    "ax.set_xticks(range(len(classes_sorted)))\n",
    "ax.set_xticklabels(classes_sorted, rotation=45)\n",
    "ax.set_ylabel('Number of Samples')\n",
    "ax.set_title('CIFAR-10 Training Set Class Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTest set size per class (expected ~1000 per class): {len(testset) // num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Visual Examples from Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 3 random samples from each class\n",
    "fig, axes = plt.subplots(num_classes, 3, figsize=(12, 16))\n",
    "fig.suptitle('Sample Images from Each CIFAR-10 Class', fontsize=16)\n",
    "\n",
    "for class_idx, class_name in enumerate(class_names):\n",
    "    # Find indices of this class\n",
    "    class_indices = [i for i, (_, label) in enumerate(trainset) if label == class_idx]\n",
    "    \n",
    "    # Randomly select 3\n",
    "    selected = np.random.choice(class_indices, 3, replace=False)\n",
    "    \n",
    "    for col, img_idx in enumerate(selected):\n",
    "        img, _ = trainset[img_idx]\n",
    "        # Convert from (C, H, W) to (H, W, C) for display\n",
    "        img_display = img.permute(1, 2, 0).numpy()\n",
    "        # Denormalize if needed (CIFAR-10 is already in [0, 1])\n",
    "        \n",
    "        axes[class_idx, col].imshow(img_display)\n",
    "        axes[class_idx, col].set_title(f\"{class_name}\")\n",
    "        axes[class_idx, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pixel statistics\n",
    "print(\"\\n=== Pixel Value Statistics ===\")\n",
    "\n",
    "all_pixels = []\n",
    "for img, _ in trainset:\n",
    "    all_pixels.append(img.view(-1).numpy())\n",
    "\n",
    "all_pixels = np.concatenate(all_pixels)\n",
    "\n",
    "print(f\"Global pixel mean: {all_pixels.mean():.4f}\")\n",
    "print(f\"Global pixel std: {all_pixels.std():.4f}\")\n",
    "print(f\"Pixel min: {all_pixels.min():.4f}\")\n",
    "print(f\"Pixel max: {all_pixels.max():.4f}\")\n",
    "\n",
    "# Plot histogram\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(all_pixels, bins=50, color='steelblue', alpha=0.7)\n",
    "ax.set_xlabel('Pixel Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Pixel Values in CIFAR-10')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 EDA Summary & Justification for Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = f\"\"\"\n",
    "=== DATASET EXPLORATION SUMMARY ===\n",
    "\n",
    "1. DATASET SIZE:\n",
    "   - Training samples: {len(trainset)}\n",
    "   - Test samples: {len(testset)}\n",
    "   - Balanced classes: Yes ({len(trainset) // num_classes} samples per class)\n",
    "\n",
    "2. IMAGE STRUCTURE:\n",
    "   - Dimensions: {sample_img.shape[1]} x {sample_img.shape[2]} pixels\n",
    "   - Channels: {sample_img.shape[0]} (RGB color images)\n",
    "   - Value range: [{all_pixels.min():.3f}, {all_pixels.max():.3f}]\n",
    "\n",
    "3. CLASSES:\n",
    "   - Number of classes: {num_classes}\n",
    "   - Balanced distribution: Yes\n",
    "\n",
    "4. WHY CONVOLUTIONAL LAYERS ARE APPROPRIATE:\n",
    "   - Small, fixed-size images (32x32) with spatial structure\n",
    "   - RGB color images where local patterns matter (e.g., edges, textures)\n",
    "   - Natural inductive bias: shift invariance and parameter sharing\n",
    "   - Significantly fewer parameters than fully connected layers\n",
    "   - Well-suited for object recognition tasks\n",
    "\n",
    "5. PREPROCESSING NEEDED:\n",
    "   - Normalization: Optional (images already in [0, 1])\n",
    "   - Resizing: Not needed (already 32x32)\n",
    "   - Augmentation: Will be applied during training for robustness\n",
    "\"\"\"\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Baseline Model (Non-Convolutional)\\n\\nTo be implemented next..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for Step 2\n",
    "print(\"Step 2: Baseline model coming next...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
